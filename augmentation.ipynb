{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./yolodata/train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the counts of the classes to get an idea of the number of images to augment for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 504\n",
      "1 68\n",
      "2 910\n",
      "3 3062\n",
      "4 825\n",
      "5 56\n",
      "6 1\n",
      "7 820\n",
      "8 388\n",
      "9 905\n",
      "10 58\n"
     ]
    }
   ],
   "source": [
    "## Number of Images for each class\n",
    "for i in range(11):\n",
    "    print(i,len(df[df['class']==i*1.0].groupby('image_path')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0     6856\n",
       "4.0     2167\n",
       "2.0     2102\n",
       "9.0     1814\n",
       "7.0     1242\n",
       "0.0      929\n",
       "8.0      599\n",
       "10.0      99\n",
       "1.0       91\n",
       "5.0       68\n",
       "6.0        1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Number of Objects for each class\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE_PATH=\"./yolodata/images/train/\"\n",
    "BASE_LABEL_PATH=\"./yolodata/labels/train/\"\n",
    "## Create these folders before running\n",
    "NEW_IMAGE_PATH=\"./yolodata_aug/images/train/\"\n",
    "NEW_LABEL_PATH=\"./yolodata_aug/labels/train/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirically decided annotation counts for each class based on number of objects and images for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations_cnt={\n",
    "    '0': 5,\n",
    "    '1': 20,\n",
    "    '2': 2,\n",
    "    '3': 0,\n",
    "    '4': 1,\n",
    "    '5': 20,\n",
    "    '6': 2,\n",
    "    '7': 5,\n",
    "    '8': 1,\n",
    "    '9': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(BASE_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_cnt=defaultdict(int) uncomment to also calculate final counts of the class distribution in the augmented images\n",
    "all_images=[]\n",
    "all_bboxes=[]\n",
    "img_names=[]\n",
    "num_aug=-1\n",
    "for id,file in enumerate(tqdm(files)):\n",
    "    img=np.array(cv2.imread(BASE_IMAGE_PATH+files[0]))\n",
    "\n",
    "    label_file=BASE_LABEL_PATH+file.replace('jpg','txt')\n",
    "    class_contri=defaultdict(int)\n",
    "    \n",
    "    bboxes=[]\n",
    "    with open(label_file,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            class_contri[line.split()[0]]+=1\n",
    "            x_c,y_c,w,h=float(line.split()[1])*640, float(line.split()[2])*640, float(line.split()[3])*640, float(line.split()[4][:-1])*640\n",
    "            bboxes.append(\n",
    "                BoundingBox(x1=x_c-(w/2), y1=y_c-(h/2), x2=x_c+(w/2), y2=y_c+(h/2),label=line.split()[0]),\n",
    "            )\n",
    "    bboxes=BoundingBoxesOnImage(bboxes,shape=img.shape)\n",
    "    num_aug=0\n",
    "    for k,v in class_contri.items():\n",
    "        if k=='3':\n",
    "            num_aug=0\n",
    "            break\n",
    "        num_aug+=augmentations_cnt[k]/v\n",
    "    num_aug/=len(class_contri)\n",
    "    num_aug=int(num_aug)\n",
    "    ## uncomment to also calculate final counts of the class distribution in the augmented images\n",
    "    # for k,v in class_contri.items():\n",
    "    #     final_cnt[k]+=(num_aug+1)*v\n",
    "    all_images.extend([img]*(num_aug+1))\n",
    "    img_names.extend([file]*(num_aug+1))\n",
    "    all_bboxes.extend([bboxes]*(num_aug+1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts after augmentation: \n",
    "\n",
    "    {'3': 6856,\n",
    "    '8': 2065,\n",
    "    '4': 2589,\n",
    "    '2': 3170,\n",
    "    '7': 1577,\n",
    "    '5': 842,\n",
    "    '6': 2516,\n",
    "    '0': 2723,\n",
    "    '9': 863,\n",
    "    '1': 789}\n",
    "              \n",
    " Total Count: 23990\n",
    "\n",
    " Much More balanced than the earlier class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.seed(3407)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        sometimes(iaa.GaussianBlur((0, 3.0))),\n",
    "        sometimes(iaa.AverageBlur(k=(2, 7))),\n",
    "        sometimes(iaa.MedianBlur(k=(3, 11))),\n",
    "        iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),\n",
    "        iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),\n",
    "        iaa.AdditiveGaussianNoise(\n",
    "                    loc=0, scale=(0.0, 0.05*255), per_channel=0.5\n",
    "                ),\n",
    "        iaa.LinearContrast((0.5, 2.0), per_channel=0.5),\n",
    "        sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),\n",
    "        sometimes(\n",
    "                    iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)\n",
    "                ),\n",
    "    ],random_order=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_aug,bboxes_aug = seq(images=all_images,bounding_boxes=all_bboxes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenting the images and saving it in the new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id,img_name in enumerate(img_names):\n",
    "    label_file=img_name.replace('jpg','txt')\n",
    "    \n",
    "    final_annots=[]\n",
    "    bboxes_aug[id]=bboxes_aug[id].remove_out_of_image().clip_out_of_image()\n",
    "    for i,bbox in enumerate(bboxes_aug[id]):\n",
    "        annot_text=str(bbox.label)+\" \"\n",
    "        x_1,y_1,x_2,y_2=bbox.x1/640, bbox.y1/640, bbox.x2/640, bbox.y2/640\n",
    "        annot_text+=str((x_1+x_2)/2)+\" \"+str((y_1+y_2)/2)+\" \"+str(x_2-x_1)+\" \"+str(y_2-y_1)+\"\\n\"\n",
    "        final_annots.append(annot_text)\n",
    "    \n",
    "    with open(NEW_LABEL_PATH+label_file.split('.')[0]+\"_\"+str(id)+\".txt\",\"w\") as f:\n",
    "        f.writelines(final_annots)\n",
    "\n",
    "    cv2.imwrite(NEW_IMAGE_PATH+img_name.split('.')[0]+\"_\"+str(id)+\".jpg\",images_aug[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
